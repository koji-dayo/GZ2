{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a3ef9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"../../data/data9size20.csv\")\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae5324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "size = 64\n",
    "for i in range(len(df)):\n",
    "    img_list.append(cv2.resize(cv2.imread(\"../../\"+df.PATH[i]),(size,size)))\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(img_list, y, test_size=0.2,random_state=1)\n",
    "X_test,X_val,y_test,y_val = train_test_split(X_test, y_test, test_size=0.5,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c9915eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "X_train,X_val,X_test = np.array(X_train)/255.,np.array(X_val)/255.,np.array(X_test)/255.\n",
    "y_train,y_val,y_test =  to_categorical((np.array(y_train)),9),to_categorical((np.array(y_val)),9),to_categorical((np.array(y_test)),9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cef0671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 60, 60, 8)         608       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 30, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 16)        3216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 63,673\n",
      "Trainable params: 63,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers,models,initializers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import sys\n",
    "def model_build():\n",
    "    size = 64\n",
    "    factor=1e-5\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(8, (5, 5), activation='relu', kernel_regularizer=l2(factor),input_shape=(size, size, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "    model.add(layers.Conv2D(16, (5, 5), activation='relu',kernel_regularizer=l2(factor)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu',kernel_regularizer=l2(factor)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu',kernel_regularizer=l2(factor)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu',kernel_regularizer=l2(factor)))\n",
    "    model.add(layers.Dense(128, activation='relu',kernel_regularizer=l2(factor)))\n",
    "    \n",
    "    model.add(layers.Dense(9, activation='softmax'))\n",
    "    #model.summary()\n",
    "    return model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "model = model_build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e7608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "284/284 [==============================] - 14s 46ms/step - loss: 1.6266 - accuracy: 0.4326 - val_loss: 1.2351 - val_accuracy: 0.5615\n",
      "Epoch 2/20\n",
      "284/284 [==============================] - 13s 45ms/step - loss: 1.2300 - accuracy: 0.5586 - val_loss: 1.1380 - val_accuracy: 0.5924\n",
      "Epoch 3/20\n",
      "284/284 [==============================] - 13s 45ms/step - loss: 1.1497 - accuracy: 0.5886 - val_loss: 1.0978 - val_accuracy: 0.6082\n",
      "Epoch 4/20\n",
      "284/284 [==============================] - 13s 45ms/step - loss: 1.0902 - accuracy: 0.6127 - val_loss: 1.0399 - val_accuracy: 0.6263\n",
      "Epoch 5/20\n",
      "284/284 [==============================] - 13s 45ms/step - loss: 1.0386 - accuracy: 0.6294 - val_loss: 1.0020 - val_accuracy: 0.6369\n",
      "Epoch 6/20\n",
      "284/284 [==============================] - 13s 45ms/step - loss: 0.9816 - accuracy: 0.6481 - val_loss: 0.9510 - val_accuracy: 0.6587\n",
      "Epoch 7/20\n",
      "284/284 [==============================] - 13s 45ms/step - loss: 0.9468 - accuracy: 0.6616 - val_loss: 0.9091 - val_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "284/284 [==============================] - 13s 45ms/step - loss: 0.8992 - accuracy: 0.6725 - val_loss: 0.9172 - val_accuracy: 0.6691\n",
      "Epoch 9/20\n",
      "284/284 [==============================] - 13s 45ms/step - loss: 0.8852 - accuracy: 0.6768 - val_loss: 0.8774 - val_accuracy: 0.6775\n",
      "Epoch 10/20\n",
      "284/284 [==============================] - 13s 45ms/step - loss: 0.8553 - accuracy: 0.6881 - val_loss: 0.8713 - val_accuracy: 0.6817\n",
      "Epoch 11/20\n",
      "284/284 [==============================] - 13s 45ms/step - loss: 0.8484 - accuracy: 0.6875 - val_loss: 0.8521 - val_accuracy: 0.6861\n",
      "Epoch 12/20\n",
      "284/284 [==============================] - 13s 45ms/step - loss: 0.8329 - accuracy: 0.6946 - val_loss: 0.8493 - val_accuracy: 0.6834\n",
      "Epoch 13/20\n",
      " 37/284 [==>...........................] - ETA: 10s - loss: 0.8332 - accuracy: 0.6934"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import datetime\n",
    "#model = model_build(1e-5, 0.3)\n",
    "model.compile(\n",
    "   optimizer = 'adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "#tsb = TensorBoard(log_dir='./logs')\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          validation_data=(X_val,y_val), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ba203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.epoch, history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(history.epoch, history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.epoch, history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.plot(history.epoch, history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0,batch_size=128)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d45bf98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
